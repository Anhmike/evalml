{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EvalML Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Components are the lowest level of building blocks in EvalML. Each component represents a fundamental operation to be applied to data.\n",
    "\n",
    "All components accept parameters as keyword arguments to their `__init__` methods. These parameters can be used to configure behavior.\n",
    "\n",
    "Each component class definition must include a human-readable `name` for the component. Additionally, each component class may expose parameters for AutoML search by defining a `hyperparameter_ranges` attribute containing the parameters in question.\n",
    "\n",
    "EvalML splits components into two categories: **transformers** and **estimators**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformers\n",
    "\n",
    "Transformers subclass the `Transformer` class, and define a `fit` method to learn information from training data and a `transform` method to apply a learned transformation to new data.\n",
    "\n",
    "For example, an [imputer](../generated/evalml.pipelines.components.SimpleImputer.ipynb) is configured with the desired impute strategy to follow, for instance the mean value. The imputers `fit` method would learn the mean from the training data, and the `transform` method would fill the learned mean value in for any missing values in new data.\n",
    "\n",
    "All transformers can execute `fit` and `transform` separately or in one step by calling `fit_transform`. Defining a custom `fit_transform` method can facilitate useful performance optimizations in some cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from evalml.pipelines.components import SimpleImputer\n",
    "\n",
    "X = pd.DataFrame([[1, 2, 3], [1, np.nan, 3]])\n",
    "display(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(impute_strategy=\"mean\")\n",
    "X = imp.fit_transform(X)\n",
    "\n",
    "display(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a list of all transformers included with EvalML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalml.pipelines.components.utils import all_components, Estimator, Transformer\n",
    "for component in all_components:\n",
    "    if issubclass(component, Transformer):\n",
    "        print(f\"Transformer: {component.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimators\n",
    "\n",
    "Each estimator wraps an ML algorithm. Estimators subclass the `Estimator` class, and define a `fit` method to learn information from training data and a `predict` method for generating predictions from new data. Classification estimators should also define a `predict_proba` method for generating predicted probabilities.\n",
    "\n",
    "Estimator classes each define a `model_family` attribute indicating what type of model is used.\n",
    "\n",
    "Here's an example of using the [LogisticRegressionClassifier](../generated/evalml.pipelines.components.LogisticRegressionClassifier.ipynb) estimator to fit and predict on a simple dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalml.pipelines.components import LogisticRegressionClassifier\n",
    "\n",
    "clf = LogisticRegressionClassifier()\n",
    "\n",
    "X = X\n",
    "y = [1, 0]\n",
    "\n",
    "clf.fit(X, y)\n",
    "clf.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a list of all estimators included with EvalML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalml.pipelines.components.utils import all_components, Estimator, Transformer\n",
    "for component in all_components:\n",
    "    if issubclass(component, Estimator):\n",
    "        print(f\"Estimator: {component.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Custom Components\n",
    "\n",
    "EvalML allows you to easily create your own custom components if you follow the below steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Inheritance\n",
    "\n",
    "Your custom component must inherit from the correct subclass: `Transformer` for components that transform data or `Estimator` for components that predict new values. Both [Transformer](../generated/evalml.pipelines.components.Transformer.ipynb) and [Estimator](../generated/evalml.pipelines.components.Estimator.ipynb) are subclasses of [ComponentBase](../generated/evalml.pipelines.components.ComponentBase.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalml.pipelines import Transformer, Estimator\n",
    "\n",
    "class NewTransformer(Transformer):\n",
    "    pass\n",
    "\n",
    "class NewEstimator(Estimator):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required fields\n",
    "\n",
    "Moreover, your component must override certain fields so that it will work with EvalML pipelines and AutoML. Subclassing without these fields will result in an error.\n",
    "\n",
    "For a component you need to provide:\n",
    "- `name` - component's name\n",
    "\n",
    "- `hyperparameter_ranges` - dictionary of parameter (string) to range ([SkOpt Space](https://scikit-optimize.github.io/stable/modules/classes.html#module-skopt.space.space)) pairings\n",
    "\n",
    "Additionaly for an estimator you need to provide:\n",
    "- `name` - component's name\n",
    "\n",
    "- `model_family` - EvalML [model_family](../generated/evalml.model_family.ModelFamily.ipynb) that this component belongs to\n",
    "\n",
    "- `supported_problem_types` - list of EvalML [problem_types](../generated/evalml.problem_types.ProblemTypes.ipynb) that this component supports\n",
    "\n",
    "Model families and problem types include:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalml.model_family import ModelFamily\n",
    "from evalml.problem_types import ProblemTypes\n",
    "\n",
    "print([m.value for m in ModelFamily])\n",
    "print([p.value for p in ProblemTypes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Integer, Real\n",
    "\n",
    "class NewTransformer(Transformer):\n",
    "    name = 'New Transformer'\n",
    "    hyperparameter_ranges = {\n",
    "        \"parameter_1\":['a', 'b', 'c']\n",
    "    }\n",
    "    \n",
    "class NewEstimator(Estimator):\n",
    "    name = 'New Estimator'\n",
    "    model_family = ModelFamily.LINEAR_MODEL\n",
    "    supported_problem_types = [ProblemTypes.BINARY, ProblemTypes.MULTICLASS]\n",
    "    hyperparameter_ranges = {\n",
    "        \"parameter_1\": Integer(10, 1000),\n",
    "        \"parameter_2\": Real(0.000001, 1),\n",
    "    }\n",
    "\n",
    "transformer = NewTransformer()\n",
    "estimator = NewEstimator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "EvalML components by default work off of a `component_object` that provides the implementation for methods such as `fit()`, `predict()`, and `transform()`. This can be seen in [ComponentBase](../generated/evalml.pipelines.components.ComponentBase.ipynb) where the base class calls the `fit()` method of the `component_obj`. This applies to both transformers and estimators. You can provide this `component_obj` in the `__init__()` method of your new component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `__init__()` method of `ComponentBase` takes in three parameters: a `parameters` dictionary holding the parameters to the component, the `component_obj` described above, and the `random_state` value. The `__init__()` method of your custom component will need to call super and pass these three parameters in. A simple example to follow is the implementation of [SimpleImputer](../generated/evalml.pipelines.components.SimpleImputer.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewTransformer(Transformer):\n",
    "    name = 'New Transformer'\n",
    "    hyperparameter_ranges = {\n",
    "        \"parameter_1\":['a', 'b', 'c']\n",
    "    }\n",
    "    \n",
    "    def __init__(self, parameter_1, random_state):\n",
    "        transformer = ThirdPartyTransformer(parameter_1)\n",
    "        parameters = {\"parameter_1\": parameter_1}\n",
    "        super().__init__(parameters=parameters,\n",
    "                         component_obj=transformer,\n",
    "                         random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, if your `component_obj` does not adhere to the same API as EvalML `Transformer`s or `Estimator`s you may need to override the correct methods. Please refer to the [API reference](https://evalml.alteryx.com/en/latest/api_reference.html#components) on each baseclass's API and implementation. An example of this can be seen in implementation of [`CatboostClassifier`](../generated/evalml.pipelines.components.CatBoostClassifier.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewEstimator(Estimator):\n",
    "    name = 'New Estimator'\n",
    "    model_family = ModelFamily.LINEAR_MODEL\n",
    "    supported_problem_types = [ProblemTypes.BINARY, ProblemTypes.MULTICLASS]\n",
    "    hyperparameter_ranges = {\n",
    "        \"parameter_1\": Integer(10, 1000),\n",
    "        \"parameter_2\": Real(0.000001, 1),\n",
    "    }\n",
    "    \n",
    "    def __init__(self, parameter_1, parameter_2, random_state):\n",
    "        transformer = ThirdPartyEstimator(parameter_1, parameter_2)\n",
    "        parameters = {\"parameter_1\": parameter_1,\n",
    "                      \"parameter_2\": parameter_2}\n",
    "        super().__init__(parameters=parameters,\n",
    "                         component_obj=transformer,\n",
    "                         random_state=random_state)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.component_obj.validate_data(X, y)\n",
    "        return self.component_obj.fit(X, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.component_obj.predicts(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if your component does not require a `component_obj`, you will need to override all methods you intend on using. This can be seen in [DropNullColumns](../generated/evalml.pipelines.components.DropNullColumns.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation Requirements\n",
    "Evalml with operate under certain assumptions if your component would be used with pipelines.\n",
    "\n",
    "#### Estimators\n",
    "- target expected as int from 0 to n-1\n",
    "- `predict_proba` column order must match the class integers and column names are set to integer values\n",
    "- no support expected for str targets at estimator level"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
